{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Local MCP Client with LlamaIndex\n",
    "\n",
    "This Jupyter notebook walks you through creating a **local MCP (Model Context Protocol) client** that can chat with a database through tools exposed by an MCP server—completely on your machine. Follow the cells in order for a smooth, self‑contained tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import Settings\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "from llama_index.core.workflow import Context\n",
    "from llama_index.core.agent.workflow import ToolCallResult, ToolCall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2  Setup a local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.6.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-core<0.13,>=0.12.4 (from llama-index-llms-ollama)\n",
      "  Downloading llama_index_core-0.12.48-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ollama>=0.5.1 (from llama-index-llms-ollama)\n",
      "  Downloading ollama-0.5.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting aiohttp<4,>=3.8.6 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading aiohttp-3.12.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiosqlite (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading aiosqlite-0.21.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.0.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading banks-2.1.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2024.6.1)\n",
      "Collecting httpx (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting llama-index-workflows<2,>=1.0.1 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading llama_index_workflows-1.1.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.3)\n",
      "Collecting nltk>3.8.1 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.1.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (11.0.0)\n",
      "Collecting pydantic>=2.8.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pyyaml>=6.0.1 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting setuptools>=80.9.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sqlalchemy>=1.4.49 (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken>=0.7.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm<5,>=4.66.1 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (4.14.1)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading multidict-6.6.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting griffe (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading griffe-1.7.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: jinja2 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (3.1.4)\n",
      "Requirement already satisfied: platformdirs in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (4.3.8)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl.metadata (252 bytes)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting click (from nltk>3.8.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting anyio (from httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading certifi-2025.7.9-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (25.0)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.4->llama-index-llms-ollama) (2.1.5)\n",
      "Downloading llama_index_llms_ollama-0.6.2-py3-none-any.whl (8.1 kB)\n",
      "Downloading llama_index_core-0.12.48-py3-none-any.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.12.14-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading banks-2.1.3-py3-none-any.whl (28 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading llama_index_workflows-1.1.0-py3-none-any.whl (37 kB)\n",
      "Downloading multidict-6.6.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (246 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (348 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (235 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading llama_index_instrumentation-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ollama-0.5.1-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.7.9-py3-none-any.whl (159 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (585 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading aiosqlite-0.21.0-py3-none-any.whl (15 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading griffe-1.7.3-py3-none-any.whl (129 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Installing collected packages: filetype, dirtyjson, wrapt, urllib3, typing-inspection, tqdm, tenacity, sniffio, setuptools, regex, pyyaml, pydantic-core, propcache, mypy-extensions, multidict, marshmallow, joblib, idna, h11, greenlet, frozenlist, colorama, click, charset_normalizer, certifi, attrs, annotated-types, aiosqlite, aiohappyeyeballs, yarl, typing-inspect, sqlalchemy, requests, pydantic, nltk, httpcore, griffe, deprecated, anyio, aiosignal, tiktoken, llama-index-instrumentation, httpx, dataclasses-json, banks, aiohttp, ollama, llama-index-workflows, llama-index-core, llama-index-llms-ollama\n",
      "\u001b[2K  Attempting uninstall: setuptools5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/50\u001b[0m [tqdm]\n",
      "\u001b[2K    Found existing installation: setuptools 78.1.17m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/50\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling setuptools-78.1.1:m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/50\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled setuptools-78.1.1[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/50\u001b[0m [setuptools]\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/50\u001b[0m [llama-index-llms-ollama]\u001b[0m [llama-index-core]x-workflows]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 aiosqlite-0.21.0 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 banks-2.1.3 certifi-2025.7.9 charset_normalizer-3.4.2 click-8.2.1 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 frozenlist-1.7.0 greenlet-3.2.3 griffe-1.7.3 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 joblib-1.5.1 llama-index-core-0.12.48 llama-index-instrumentation-0.2.0 llama-index-llms-ollama-0.6.2 llama-index-workflows-1.1.0 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 nltk-3.9.1 ollama-0.5.1 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 setuptools-80.9.0 sniffio-1.3.1 sqlalchemy-2.0.41 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-inspect-0.9.0 typing-inspection-0.4.1 urllib3-2.5.0 wrapt-1.17.2 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3.2\", request_timeout=120.0)\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Initialize the MCP client and build the agent\n",
    "Point the client at your local MCP server’s **SSE endpoint** (default shown below), and list the available tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.12.48-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting llama-index-agent-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl.metadata (439 bytes)\n",
      "Collecting llama-index-cli<0.5,>=0.4.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.4.4-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.48 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index) (0.12.48)\n",
      "Collecting llama-index-embeddings-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.7.10-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-llms-openai<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.5.3-py3-none-any.whl.metadata (441 bytes)\n",
      "Collecting llama-index-program-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.3.2-py3-none-any.whl.metadata (473 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4,>=0.3.0 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl.metadata (492 bytes)\n",
      "Collecting llama-index-readers-file<0.5,>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.4.11-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index) (3.9.1)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Downloading openai-1.94.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (3.12.14)\n",
      "Requirement already satisfied: aiosqlite in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (2.1.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (2024.6.1)\n",
      "Requirement already satisfied: httpx in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (0.28.1)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (1.1.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (3.3)\n",
      "Requirement already satisfied: numpy in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (2.1.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (2.11.7)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.48->llama-index) (2.0.41)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (4.14.1)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-core<0.13,>=0.12.48->llama-index) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13,>=0.12.48->llama-index) (1.20.1)\n",
      "Requirement already satisfied: griffe in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index) (1.7.3)\n",
      "Requirement already satisfied: jinja2 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index) (3.1.4)\n",
      "Requirement already satisfied: platformdirs in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index) (4.3.8)\n",
      "Collecting beautifulsoup4<5,>=4.12.3 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting defusedxml>=0.7.1 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting pandas<2.3.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting pypdf<6,>=5.1.0 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading pypdf-5.7.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.48->llama-index) (0.2.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index)\n",
      "  Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (3.10)\n",
      "Requirement already satisfied: certifi in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.48->llama-index) (2025.7.9)\n",
      "Requirement already satisfied: httpcore==1.* in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from httpx->llama-index-core<0.13,>=0.12.48->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.48->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.48->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.48->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.48->llama-index) (0.4.1)\n",
      "Collecting llama-cloud==0.1.32 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.32-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.46-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.45 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.46-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from llama-cloud-services>=0.6.45->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.2.1)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading llama_cloud_services-0.6.45-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.45-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Downloading llama_parse-0.6.44-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting llama-cloud-services>=0.6.44 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.44-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.43-py3-none-any.whl.metadata (6.9 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.43 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.43-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.43->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: joblib in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.5,>=0.4.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.48->llama-index) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.13,>=0.12.48->llama-index) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.48->llama-index) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.48->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.48->llama-index) (3.26.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13,>=0.12.48->llama-index) (25.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vipranan/miniconda3/envs/pycode/lib/python3.11/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.48->llama-index) (2.1.5)\n",
      "Downloading llama_index-0.12.48-py3-none-any.whl (7.1 kB)\n",
      "Downloading llama_index_agent_openai-0.4.12-py3-none-any.whl (14 kB)\n",
      "Downloading llama_index_cli-0.4.4-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_llms_openai-0.4.7-py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.5.3-py3-none-any.whl (3.4 kB)\n",
      "Downloading llama_index_program_openai-0.3.2-py3-none-any.whl (6.1 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.1-py3-none-any.whl (3.7 kB)\n",
      "Downloading llama_index_readers_file-0.4.11-py3-none-any.whl (41 kB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Downloading openai-1.94.0-py3-none-any.whl (755 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.2/755.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-5.7.0-py3-none-any.whl (305 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.7.10-py3-none-any.whl (16 kB)\n",
      "Downloading llama_cloud-0.1.32-py3-none-any.whl (284 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Downloading llama_parse-0.6.43-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.43-py3-none-any.whl (40 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: striprtf, pytz, tzdata, soupsieve, python-dotenv, pypdf, jiter, distro, defusedxml, pandas, beautifulsoup4, openai, llama-cloud, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-readers-llama-parse, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26/26\u001b[0m [llama-index]━━━━\u001b[0m \u001b[32m20/26\u001b[0m [llama-index-cli]\n",
      "\u001b[1A\u001b[2KSuccessfully installed beautifulsoup4-4.13.4 defusedxml-0.7.1 distro-1.9.0 jiter-0.10.0 llama-cloud-0.1.32 llama-cloud-services-0.6.43 llama-index-0.12.48 llama-index-agent-openai-0.4.12 llama-index-cli-0.4.4 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.7.10 llama-index-llms-openai-0.4.7 llama-index-multi-modal-llms-openai-0.5.3 llama-index-program-openai-0.3.2 llama-index-question-gen-openai-0.3.1 llama-index-readers-file-0.4.11 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.43 openai-1.94.0 pandas-2.2.3 pypdf-5.7.0 python-dotenv-1.1.1 pytz-2025.2 soupsieve-2.7 striprtf-0.0.26 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall llama-index\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmcp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BasicMCPClient, McpToolSpec\n\u001b[32m      5\u001b[39m mcp_client = BasicMCPClient(\u001b[33m\"\u001b[39m\u001b[33mhttp://127.0.0.1:8000/sse\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m mcp_tools = McpToolSpec(client=mcp_client) \u001b[38;5;66;03m# you can also pass list of allowed tools\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_index.tools'"
     ]
    }
   ],
   "source": [
    "%pip install llama-index\n",
    "\n",
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mcp_tool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tools = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43mmcp_tool\u001b[49m.to_tool_list_async()\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(tool.metadata.name, tool.metadata.description)\n",
      "\u001b[31mNameError\u001b[39m: name 'mcp_tool' is not defined"
     ]
    }
   ],
   "source": [
    "tools = await mcp_tool.to_tool_list_async()\n",
    "for tool in tools:\n",
    "    print(tool.metadata.name, tool.metadata.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3  Define the system prompt\n",
    "This prompt steers the LLM when it needs to decide how and when to call tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\\\n",
    "You are an AI assistant for Tool Calling.\n",
    "\n",
    "Before you help a user, you need to work with tools to interact with Our Database\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4  Helper function: `get_agent()`\n",
    "Creates a `FunctionAgent` wired up with the MCP tool list and your chosen LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import McpToolSpec\n",
    "from llama_index.core.agent.workflow import FunctionAgent\n",
    "\n",
    "async def get_agent(tools: McpToolSpec):\n",
    "    tools = await tools.to_tool_list_async()\n",
    "    agent = FunctionAgent(\n",
    "        name=\"Agent\",\n",
    "        description=\"An agent that can work with Our Database software.\",\n",
    "        tools=tools,\n",
    "        llm=OpenAI(model=\"gpt-4\"),\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "    )\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5  Helper function: `handle_user_message()`\n",
    "Streams intermediate tool calls (for transparency) and returns the final response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    FunctionAgent, \n",
    "    ToolCallResult, \n",
    "    ToolCall)\n",
    "\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "async def handle_user_message(\n",
    "    message_content: str,\n",
    "    agent: FunctionAgent,\n",
    "    agent_context: Context,\n",
    "    verbose: bool = False,\n",
    "):\n",
    "    handler = agent.run(message_content, ctx=agent_context)\n",
    "    async for event in handler.stream_events():\n",
    "        if verbose and type(event) == ToolCall:\n",
    "            print(f\"Calling tool {event.tool_name} with kwargs {event.tool_kwargs}\")\n",
    "        elif verbose and type(event) == ToolCallResult:\n",
    "            print(f\"Tool {event.tool_name} returned {event.tool_output}\")\n",
    "\n",
    "    response = await handler\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6  Initialize the MCP client and build the agent\n",
    "Point the client at your local MCP server’s **SSE endpoint** (default shown below), build the agent, and setup agent context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.mcp import BasicMCPClient, McpToolSpec\n",
    "\n",
    "\n",
    "mcp_client = BasicMCPClient(\"http://127.0.0.1:8000/sse\")\n",
    "mcp_tool = McpToolSpec(client=mcp_client)\n",
    "\n",
    "# get the agent\n",
    "agent = await get_agent(mcp_tool)\n",
    "\n",
    "# create the agent context\n",
    "agent_context = Context(agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Add to the db: Rafael Nadal whose age is 39 and is a tennis player\n",
      "Calling tool add_data with kwargs {'query': \"INSERT INTO people (name, age, profession) VALUES ('Rafael Nadal', 39, 'Tennis Player')\"}\n",
      "Tool add_data returned meta=None content=[TextContent(type='text', text='true', annotations=None)] isError=False\n",
      "Agent:  The data has been added successfully.\n",
      "User:  fetch data\n",
      "Calling tool read_data with kwargs {'query': 'SELECT * FROM people'}\n",
      "Tool read_data returned meta=None content=[TextContent(type='text', text='1', annotations=None), TextContent(type='text', text='Rafael Nadal', annotations=None), TextContent(type='text', text='39', annotations=None), TextContent(type='text', text='Tennis Player', annotations=None)] isError=False\n",
      "Agent:  Here is the data from the database:\n",
      "\n",
      "1. ID: 1\n",
      "   Name: Rafael Nadal\n",
      "   Age: 39\n",
      "   Profession: Tennis Player\n",
      "User:  add to the db: Roger federer whose age is 42 and is a tennis player\n",
      "Calling tool add_data with kwargs {'query': \"INSERT INTO people (name, age, profession) VALUES ('Roger Federer', 42, 'Tennis Player')\"}\n",
      "Tool add_data returned meta=None content=[TextContent(type='text', text='true', annotations=None)] isError=False\n",
      "Agent:  The data has been added successfully.\n",
      "User:  fetch data\n",
      "Calling tool read_data with kwargs {'query': 'SELECT * FROM people'}\n",
      "Tool read_data returned meta=None content=[TextContent(type='text', text='1', annotations=None), TextContent(type='text', text='Rafael Nadal', annotations=None), TextContent(type='text', text='39', annotations=None), TextContent(type='text', text='Tennis Player', annotations=None), TextContent(type='text', text='2', annotations=None), TextContent(type='text', text='Roger Federer', annotations=None), TextContent(type='text', text='42', annotations=None), TextContent(type='text', text='Tennis Player', annotations=None)] isError=False\n",
      "Agent:  Here is the data from the database:\n",
      "\n",
      "1. ID: 1\n",
      "   Name: Rafael Nadal\n",
      "   Age: 39\n",
      "   Profession: Tennis Player\n",
      "\n",
      "2. ID: 2\n",
      "   Name: Roger Federer\n",
      "   Age: 42\n",
      "   Profession: Tennis Player\n"
     ]
    }
   ],
   "source": [
    "# Run the agent!\n",
    "while True:\n",
    "    user_input = input(\"Enter your message: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    print(\"User: \", user_input)\n",
    "    response = await handle_user_message(user_input, agent, agent_context, verbose=True)\n",
    "    print(\"Agent: \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pycode)",
   "language": "python",
   "name": "pycode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
